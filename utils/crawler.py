import requests
from bs4 import BeautifulSoup
import json
import os

FDA_URL = "https://www.fda.gov/drugs/drug-safety-and-availability/drug-safety-communications"
CACHE_PATH = "data/fda_cache.json"

def fetch_fda_dsc_alerts():
    """æŠ“å– FDA å®˜ç¶² Drug Safety Communications é é¢ï¼Œå›å‚³ alerts æ¸…å–®"""
    try:
        resp = requests.get(FDA_URL, timeout=10)
        if resp.status_code != 200:
            print("âš ï¸ FDA å®˜ç¶²é€£ç·šå¤±æ•—ï¼Œç‹€æ…‹ç¢¼ï¼š", resp.status_code)
            return []

        soup = BeautifulSoup(resp.text, "html.parser")

        alerts = []
        # æŠ“å–æ¯ç¯‡ DSC çš„æ¨™é¡Œèˆ‡é€£çµ
        for item in soup.select("div.views-row a"):
            title = item.get_text(strip=True)
            link = item.get("href", "")
            if title and link:
                alerts.append({"title": title, "link": link})

        print("âœ… æˆåŠŸæŠ“å– FDA è­¦ç¤ºæ•¸é‡ï¼š", len(alerts))
        return alerts

    except Exception as e:
        print("âŒ æŠ“å– FDA å®˜ç¶²å¤±æ•—ï¼š", e)
        return []

def parse_dsc_to_fda_list(alerts):
    """å°‡ alerts è½‰æ›æˆæ¨™æº–åŒ–çš„ fda_list çµæ§‹"""
    if not alerts:
        print("âš ï¸ è­¦ç¤ºæ¸…å–®ç‚ºç©ºï¼Œä½¿ç”¨å‚™æ´è³‡æ–™")
        from utils.fallback_data import fda_list
        return fda_list

    fda_list = []
    for alert in alerts:
        fda_list.append({
            "alert_date": "",  # å®˜ç¶²éœ€é€²ä¸€æ­¥è§£ææ—¥æœŸï¼Œå¯æ“´å……
            "source": "FDA",
            "us_product": alert["title"],
            "ingredient": "æœªçŸ¥",
            "form": "æœªçŸ¥",
            "risk_summary": "å°šæœªè§£æï¼Œè«‹åƒè€ƒ FDA åŸæ–‡",
            "action_summary": "å°šæœªè§£æï¼Œè«‹åƒè€ƒ FDA åŸæ–‡",
            "fda_excerpt": f"https://www.fda.gov{alert['link']}"
        })

    print("âœ… æˆåŠŸè½‰æ› fda_list æ•¸é‡ï¼š", len(fda_list))
    return fda_list

def get_new_alerts():
    """æ¯”å°å¿«å–ï¼Œå›å‚³æ–°è­¦ç¤º"""
    latest = fetch_fda_dsc_alerts()
    latest_titles = {a["title"] for a in latest}

    if os.path.exists(CACHE_PATH):
        with open(CACHE_PATH, "r", encoding="utf-8") as f:
            cached = json.load(f)
        cached_titles = {a["title"] for a in cached}
    else:
        cached_titles = set()

    new_titles = latest_titles - cached_titles
    new_alerts = [a for a in latest if a["title"] in new_titles]

    # æ›´æ–°å¿«å–
    try:
        with open(CACHE_PATH, "w", encoding="utf-8") as f:
            json.dump(latest, f, ensure_ascii=False, indent=2)
        print("âœ… å¿«å–å·²æ›´æ–°")
    except Exception as e:
        print("âš ï¸ å¿«å–æ›´æ–°å¤±æ•—ï¼š", e)

    print(f"ğŸ” æ–°è­¦ç¤ºæ•¸é‡ï¼š{len(new_alerts)}")
    return new_alerts
