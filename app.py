import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from difflib import SequenceMatcher
import os

def normalize_text(text):
    if not text:
        return ""
    return (
        str(text).lower()
        .replace(" ", "")
        .replace("åŠ‘", "")
        .replace("æ³¨å°„æ¶²åŠ‘", "æ³¨å°„æ¶²")
        .replace("æ¯«å…‹", "mg")
        .replace("æ¯«å‡", "ml")
    )
def fuzzy_match(a, b):
    return SequenceMatcher(None, a, b).ratio()

def compute_match_score(fda, tfda):
    fda_ing = normalize_text(fda.get("ingredient", ""))
    tfda_ing = normalize_text(tfda.get("ingredient", ""))
    fda_form = normalize_text(fda.get("form", ""))
    tfda_form = normalize_text(tfda.get("form", ""))
    fda_prod = normalize_text(fda.get("us_product", ""))
    tfda_prod = normalize_text(tfda.get("tw_product", ""))

    score = 0.0
    if fda_ing and tfda_ing:
        if fda_ing == tfda_ing:
            score += 0.6
        elif fda_ing.split()[0] == tfda_ing.split()[0]:
            score += 0.5

    if fda_form and tfda_form:
        if fda_form == tfda_form:
            score += 0.3
        elif fda_form.split()[0] == tfda_form.split()[0]:
            score += 0.2

    if fda_prod and tfda_prod:
        sim = fuzzy_match(fda_prod, tfda_prod)
        if sim >= 0.85:
            score += 0.1
        elif sim >= 0.7:
            score += 0.05

    return round(score, 2)

def match_fda_to_tfda(fda_list, tfda_list):
    results = []
    for fda in fda_list:
        best_match = None
        best_score = 0.0
        for tfda in tfda_list:
            score = compute_match_score(fda, tfda)
            if score > best_score:
                best_score = score
                best_match = tfda
        if best_match and best_score >= 0.5:
            results.append({
                "Alert Date": fda["alert_date"],
                "Source": fda["source"],
                "US Product": fda["us_product"],
                "Ingredient": fda["ingredient"],
                "Risk Summary": fda["risk_summary"],
                "Action Summary": fda["action_summary"],
                "TW Match Status": "åŒä¸»æˆåˆ†" if best_score >= 0.85 else "ä¸­ä¿¡åº¦é…å°",
                "TW Product": best_match["tw_product"],
                "License ID": best_match["license_id"],
                "Strength/Form": best_match["form"],
                "Match Confidence": best_score,
                "FDA Excerpt": fda["fda_excerpt"]
            })
        else:
            results.append({
                "Alert Date": fda["alert_date"],
                "Source": fda["source"],
                "US Product": fda["us_product"],
                "Ingredient": fda["ingredient"],
                "Risk Summary": fda["risk_summary"],
                "Action Summary": fda["action_summary"],
                "TW Match Status": "ç„¡é…å°",
                "TW Product": "",
                "License ID": "",
                "Strength/Form": "",
                "Match Confidence": 0.0,
                "FDA Excerpt": fda["fda_excerpt"]
            })
    return results
def fetch_fda_dsc_alerts():
    url = "https://www.fda.gov/drugs/drug-safety-and-availability/drug-safety-communications"
    resp = requests.get(url)
    if resp.status_code != 200:
        return []
    soup = BeautifulSoup(resp.text, "html.parser")
    alerts = []
    # é€™è£¡è¦æ ¹æ“š FDA å®˜ç¶²çš„ HTML çµæ§‹ä¾†è§£æ
    for item in soup.select(".views-row"):
        title = item.get_text(strip=True)
        link = item.find("a")["href"] if item.find("a") else ""
        alerts.append({"title": title, "link": link})
    return alerts

def parse_dsc_to_fda_list(alerts):
    fda_list = []
    for alert in alerts:
        # TODO: è§£æ alert é é¢å…§å®¹ï¼ŒæŠ½å–æˆåˆ†ã€åŠ‘å‹ã€æ‘˜è¦ç­‰
        fda_list.append({
            "alert_date": "2025-11-20",  # éœ€å¾é é¢è§£æ
            "source": "DSC",
            "us_product": alert["title"],  # æš«ç”¨æ¨™é¡Œ
            "ingredient": "",
            "form": "",
            "risk_summary": "",
            "action_summary": "",
            "fda_excerpt": alert["link"]
        })
    return fda_list

def get_new_alerts():
    # TODO: å¯ä»¥å…ˆæŠ“å–æœ€æ–°æ¸…å–®ï¼Œèˆ‡æœ¬åœ°å¿«å–æ¯”å°
    latest = fetch_fda_dsc_alerts()
    # å‡è¨­ç›®å‰æ²’æœ‰å¿«å–ï¼Œå°±ç›´æ¥å›å‚³å…¨éƒ¨
    return latest

# é è¨­ FDA è—¥å“æ¸…å–®
fda_list = [
    {
        "alert_date": "2025-11-01",
        "source": "DSC",
        "us_product": "Leqembi",
        "ingredient": "lecanemab",
        "form": "100 mg/mL æ³¨å°„æ¶²",
        "risk_summary": "é˜¿èŒ²æµ·é»˜ç—‡ ARIAï¼šAPOE Îµ4 æ”œå¸¶è€…é¢¨éšªå¢åŠ ",
        "action_summary": "å»ºè­°åŸºå› æª¢æ¸¬",
        "fda_excerpt": "FDA recommends MRI monitoring to reduce ARIA risk, especially in APOE Îµ4 carriers."
    },
    {
        "alert_date": "2025-10-15",
        "source": "DSC",
        "us_product": "Prolia",
        "ingredient": "denosumab",
        "form": "60 mg/1 mL æ³¨å°„æ¶²",
        "risk_summary": "åš´é‡ä½è¡€éˆ£ï¼šæ´—è…ç—…äººé¢¨éšªå¢åŠ ",
        "action_summary": "å»ºè­°ç›£æ¸¬è¡€éˆ£",
        "fda_excerpt": "Risk of severe hypocalcemia in dialysis patients receiving denosumab."
    },
    {
        "alert_date": "2025-09-30",
        "source": "DSC",
        "us_product": "Ocaliva",
        "ingredient": "obeticholic acid",
        "form": "5 mg éŒ åŠ‘",
        "risk_summary": "åŸç™¼æ€§è†½æ±æ€§è‚ç¡¬åŒ–ï¼šæ™šæœŸè‚ç—…ç—…äººé¢¨éšªå¢åŠ ",
        "action_summary": "å»ºè­°èª¿æ•´åŠ‘é‡",
        "fda_excerpt": "Serious liver injury reported in non-cirrhotic PBC patients treated with obeticholic acid."
    }
]

# Streamlit ä¸»ç•«é¢
st.set_page_config(page_title="è—¥å“å®‰å…¨è­¦ç¤ºæ¯”å°å¹³å°", layout="wide")
st.title("è—¥å“å®‰å…¨è­¦ç¤ºæ¯”å°å¹³å°")

# è®€å– TFDA è¨±å¯è­‰æ¸…å–®
try:
    df_tfda = pd.read_csv("37_2b.csv")
    required_cols = ["tw_product", "ingredient", "form", "license_id"]
    if not all(col in df_tfda.columns for col in required_cols):
        st.error("âŒ 37_2b.csv æ¬„ä½ç¼ºæ¼ï¼Œè«‹ç¢ºèªåŒ…å«ï¼štw_product, ingredient, form, license_id")
        tfda_list = []
    else:
        tfda_list = df_tfda[required_cols].to_dict(orient="records")
except Exception as e:
    st.error(f"âŒ è®€å– 37_2b.csv å¤±æ•—ï¼š{e}")
    tfda_list = []

# åŸ·è¡Œé…å°
df = pd.DataFrame(match_fda_to_tfda(fda_list, tfda_list))

# é˜²å‘†æª¢æŸ¥
if df.empty:
    st.error("âš ï¸ æ²’æœ‰é…å°çµæœï¼Œè«‹ç¢ºèª TFDA è³‡æ–™èˆ‡ FDA æ¸…å–®æ ¼å¼ã€‚")
    st.stop()

missing_cols = [col for col in ["Alert Date", "Source", "US Product"] if col not in df.columns]
if missing_cols:
    st.error(f"âš ï¸ ç¼ºå°‘æ¬„ä½ï¼š{', '.join(missing_cols)}ï¼Œè«‹æª¢æŸ¥ match_fda_to_tfda() æ˜¯å¦æ­£ç¢ºç”¢ç”Ÿæ¬„ä½ã€‚")
    st.dataframe(df)
    st.stop()

df["Alert Date"] = pd.to_datetime(df["Alert Date"])
# KPI å¡ç‰‡
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric(label="æœ¬æœŸè­¦ç¤ºæ•¸", value=len(df))
with col2:
    st.metric(label="æ–°å¢é»‘æ¡†è­¦èªæ•¸", value=1)
with col3:
    st.metric(label="å°ç£æœ‰é…å°è—¥å“æ•¸", value=(df["TW Match Status"] != "ç„¡é…å°").sum())
with col4:
    st.metric(label="éœ€äººå·¥è¦†æ ¸æ•¸", value=(df["Match Confidence"] < 0.7).sum())

st.markdown("---")

# ç¯©é¸å™¨
st.sidebar.header("ç¯©é¸å™¨")
min_date = df["Alert Date"].min().date()
max_date = df["Alert Date"].max().date()
date_range = st.sidebar.date_input("è­¦ç¤ºæ—¥æœŸç¯„åœ", value=(min_date, max_date), min_value=min_date, max_value=max_date)
source_options = df["Source"].unique().tolist()
selected_sources = st.sidebar.multiselect("ä¾†æºé¡å‹", options=source_options, default=source_options)
keyword = st.sidebar.text_input("é—œéµå­—æœå°‹ï¼ˆå“å / æˆåˆ† / æ‘˜è¦ï¼‰", value="")

start_date, end_date = date_range if isinstance(date_range, tuple) else (min_date, max_date)
df_filtered = df[
    (df["Alert Date"] >= pd.to_datetime(start_date)) &
    (df["Alert Date"] <= pd.to_datetime(end_date)) &
    (df["Source"].isin(selected_sources))
]
if keyword.strip():
    kw = keyword.strip().lower()
    df_filtered = df_filtered[df_filtered.apply(lambda row: kw in str(row).lower(), axis=1)]

# ä¸»è¡¨æ ¼é¡¯ç¤º
st.markdown("### ğŸ“‹ é…å°çµæœä¸€è¦½")
st.dataframe(df_filtered, use_container_width=True)

# è©³æƒ…å±•é–‹
with st.expander("ğŸ“¦ å±•é–‹æ¯ç­†è­¦ç¤ºè©³æƒ…"):
    for _, row in df_filtered.iterrows():
        st.markdown(f"**ğŸ§ª {row['US Product']}**ï¼ˆ{row['Ingredient']}ï¼‰")
        st.markdown(f"- è­¦ç¤ºæ—¥æœŸï¼š{row['Alert Date'].date()}ï½œä¾†æºï¼š{row['Source']}")
        st.markdown(f"- å°ç£é…å°ï¼š{row['TW Match Status']} â†’ `{row['TW Product']}`")
        st.markdown(f"- æ‘˜è¦ï¼š{row['Risk Summary']}")
        st.markdown(f"- å»ºè­°ï¼š{row['Action Summary']}")
        st.markdown(f"- è©³æƒ…ï¼š{row['FDA Excerpt']}")
        st.markdown("---")

# FDA å®˜ç¶²çˆ¬èŸ²æŒ‰éˆ•
st.markdown("### ğŸ” ä¸€éµæŠ“å–ä¸¦æ¯”å° FDA å®˜ç¶²è­¦ç¤º")
if st.button("ç«‹å³æ›´æ–°"):
    latest_alerts = fetch_fda_dsc_alerts()
    fda_list_from_web = parse_dsc_to_fda_list(latest_alerts)
    df_web = pd.DataFrame(match_fda_to_tfda(fda_list_from_web, tfda_list))
    if not df_web.empty and "Alert Date" in df_web.columns:
        df_web["Alert Date"] = pd.to_datetime(df_web["Alert Date"])
        st.dataframe(df_web, use_container_width=True)
    else:
        st.warning("âš ï¸ å®˜ç¶²è­¦ç¤ºæ¯”å°å¤±æ•—æˆ–è³‡æ–™æ ¼å¼ç•°å¸¸ã€‚")

# ç¶²é ç›£è¦–ï¼šæª¢æŸ¥æ˜¯å¦æœ‰æ–°è­¦ç¤º
st.markdown("### ğŸ” æª¢æŸ¥ FDA å®˜ç¶²æ˜¯å¦æœ‰æ–°è­¦ç¤º")
if st.button("æª¢æŸ¥æ–°è­¦ç¤ºä¸¦æ¯”å°"):
    new_alerts = get_new_alerts()
    if new_alerts:
        st.success(f"ç™¼ç¾ {len(new_alerts)} ç­†æ–°è­¦ç¤ºï¼")
        fda_list_new = parse_dsc_to_fda_list(new_alerts)
        df_new = pd.DataFrame(match_fda_to_tfda(fda_list_new, tfda_list))
        if not df_new.empty and "Alert Date" in df_new.columns:
            df_new["Alert Date"] = pd.to_datetime(df_new["Alert Date"])
            st.dataframe(df_new, use_container_width=True)
        else:
            st.warning("âš ï¸ æ–°è­¦ç¤ºè³‡æ–™æ ¼å¼ç•°å¸¸ï¼Œç„¡æ³•é¡¯ç¤ºã€‚")
    else:
        st.info("ç›®å‰æ²’æœ‰æ–°è­¦ç¤ºã€‚")
