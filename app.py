import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from difflib import SequenceMatcher

def fuzzy_match(a, b):
    return SequenceMatcher(None, a.lower(), b.lower()).ratio()

def compute_match_score(fda, tfda):
    score = 0.0
    fda_ing = str(fda.get("ingredient", "")).strip()
    tfda_ing = str(tfda.get("ingredient", "")).strip()
    fda_form = str(fda.get("form", "")).strip()
    tfda_form = str(tfda.get("form", "")).strip()

    if fda_ing and tfda_ing:
        if fda_ing == tfda_ing:
            score += 0.6
        elif fda_ing.split()[0] == tfda_ing.split()[0]:
            score += 0.5

    if fda_form and tfda_form:
        if fda_form == tfda_form:
            score += 0.3
        elif fda_form.split()[0] == tfda_form.split()[0]:
            score += 0.2

    fda_prod = str(fda.get("us_product", "")).strip()
    tfda_prod = str(tfda.get("tw_product", "")).strip()
    if fda_prod and tfda_prod:
        sim = fuzzy_match(fda_prod, tfda_prod)
        if sim >= 0.85:
            score += 0.1
        elif sim >= 0.7:
            score += 0.05

    return round(score, 2)

def match_fda_to_tfda(fda_list, tfda_list):
    results = []
    for fda in fda_list:
        best_match = None
        best_score = 0.0
        for tfda in tfda_list:
            score = compute_match_score(fda, tfda)
            if score > best_score:
                best_score = score
                best_match = tfda
        if best_match and best_score >= 0.5:
            results.append({
                "Alert Date": fda["alert_date"],
                "Source": fda["source"],
                "US Product": fda["us_product"],
                "Ingredient": fda["ingredient"],
                "Risk Summary": fda["risk_summary"],
                "Action Summary": fda["action_summary"],
                "TW Match Status": "åŒä¸»æˆåˆ†" if best_score >= 0.85 else "ä¸­ä¿¡åº¦é…å°",
                "TW Product": best_match["tw_product"],
                "License ID": best_match["license_id"],
                "Strength/Form": best_match["form"],
                "Match Confidence": best_score,
                "FDA Excerpt": fda["fda_excerpt"]
            })
        else:
            results.append({
                "Alert Date": fda["alert_date"],
                "Source": fda["source"],
                "US Product": fda["us_product"],
                "Ingredient": fda["ingredient"],
                "Risk Summary": fda["risk_summary"],
                "Action Summary": fda["action_summary"],
                "TW Match Status": "ç„¡é…å°",
                "TW Product": "",
                "License ID": "",
                "Strength/Form": "",
                "Match Confidence": 0.0,
                "FDA Excerpt": fda["fda_excerpt"]
            })
    return results

# -------------------------
# TFDA è¨±å¯è­‰åŒ¯å…¥æ¨¡çµ„
# -------------------------
def load_tfda_file(file):
    try:
        if file.name.endswith(".csv"):
            df_tfda = pd.read_csv(file)
        else:
            df_tfda = pd.read_excel(file)
        required_cols = ["tw_product", "ingredient", "form", "license_id"]
        if not all(col in df_tfda.columns for col in required_cols):
            st.error("æ¬„ä½ç¼ºæ¼ï¼Œè«‹ç¢ºèªåŒ…å«ï¼štw_product, ingredient, form, license_id")
            return []
        return df_tfda[required_cols].to_dict(orient="records")
    except Exception as e:
        st.error(f"è®€å–å¤±æ•—ï¼š{e}")
        return []

# -------------------------
# FDA å®˜ç¶²çˆ¬èŸ²æ¨¡çµ„
# -------------------------
def fetch_fda_dsc_alerts():
    url = "https://www.fda.gov/drugs/drug-safety-and-availability/drug-safety-communications"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")

    alerts = []
    for item in soup.select(".view-content .views-row"):
        title_tag = item.select_one("h3 a")
        date_tag = item.select_one(".date-display-single")
        if title_tag and date_tag:
            alerts.append({
                "title": title_tag.text.strip(),
                "link": "https://www.fda.gov" + title_tag["href"],
                "date": date_tag.text.strip()
            })
    return alerts

# -------------------------
# FDA è­¦ç¤ºè½‰æ›æˆ fda_list çµæ§‹
# -------------------------
def parse_dsc_to_fda_list(alerts):
    parsed = []
    for alert in alerts:
        parsed.append({
            "alert_date": pd.to_datetime(alert["date"], errors="coerce"),
            "source": "DSC",
            "us_product": alert["title"].split(":")[0].strip(),
            "ingredient": "",
            "form": "",
            "risk_summary": alert["title"],
            "action_summary": "è«‹åƒè€ƒåŸæ–‡",
            "fda_excerpt": f"è©³æƒ…è«‹è¦‹ï¼š{alert['link']}"
        })
    return parsed

# -------------------------
# Streamlit ä¸»ç•«é¢
# -------------------------
st.set_page_config(page_title="è—¥å“å®‰å…¨è­¦ç¤ºæ¯”å°å¹³å°", layout="wide")
st.title("è—¥å“å®‰å…¨è­¦ç¤ºæ¯”å°å¹³å°")

# TFDA è¨±å¯è­‰åŒ¯å…¥
uploaded_file = st.sidebar.file_uploader("ä¸Šå‚³ TFDA è¨±å¯è­‰æ¸…å–®ï¼ˆCSV æˆ– Excelï¼‰", type=["csv", "xlsx"])
if uploaded_file:
    tfda_list = load_tfda_file(uploaded_file)
else:
    tfda_list = [
        {"tw_product": "æ¨‚æ„ä¿", "ingredient": "lecanemab", "form": "100 mg/mL æ³¨å°„æ¶²", "license_id": "MOHW-BI-001273"},
        {"tw_product": "éª¨æ¾ç›Š", "ingredient": "denosumab", "form": "60 mg/1 mL æ³¨å°„æ¶²", "license_id": "è¡›éƒ¨è—¥è£½å­—ç¬¬XXXXè™Ÿ"}
    ]

# é è¨­æ¯”å°çµæœ
df = pd.DataFrame(match_fda_to_tfda(fda_list, tfda_list))
df["Alert Date"] = pd.to_datetime(df["Alert Date"])

# KPI å¡ç‰‡
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric(label="æœ¬æœŸè­¦ç¤ºæ•¸", value=len(df))
with col2:
    st.metric(label="æ–°å¢é»‘æ¡†è­¦èªæ•¸", value=1)
with col3:
    st.metric(label="å°ç£æœ‰é…å°è—¥å“æ•¸", value=(df["TW Match Status"] != "ç„¡é…å°").sum())
with col4:
    st.metric(label="éœ€äººå·¥è¦†æ ¸æ•¸", value=(df["Match Confidence"] < 0.7).sum())

st.markdown("---")

# ç¯©é¸å™¨
st.sidebar.header("ç¯©é¸å™¨")
min_date = df["Alert Date"].min().date()
max_date = df["Alert Date"].max().date()
date_range = st.sidebar.date_input("è­¦ç¤ºæ—¥æœŸç¯„åœ", value=(min_date, max_date), min_value=min_date, max_value=max_date)
source_options = df["Source"].unique().tolist()
selected_sources = st.sidebar.multiselect("ä¾†æºé¡å‹", options=source_options, default=source_options)
keyword = st.sidebar.text_input("é—œéµå­—æœå°‹ï¼ˆå“å / æˆåˆ† / æ‘˜è¦ï¼‰", value="")

# å¥—ç”¨ç¯©é¸
start_date, end_date = date_range if isinstance(date_range, tuple) else (min_date, max_date)
df_filtered = df[
    (df["Alert Date"] >= pd.to_datetime(start_date)) &
    (df["Alert Date"] <= pd.to_datetime(end_date)) &
    (df["Source"].isin(selected_sources))
]
if keyword.strip():
    kw = keyword.strip().lower()
    df_filtered = df_filtered[df_filtered.apply(lambda row: kw in str(row).lower(), axis=1)]


# ä¸»è¡¨æ ¼é¡¯ç¤º
st.markdown("### ğŸ“‹ é…å°çµæœä¸€è¦½")
st.dataframe(df_filtered, use_container_width=True)

# è©³æƒ…å±•é–‹
with st.expander("ğŸ“¦ å±•é–‹æ¯ç­†è­¦ç¤ºè©³æƒ…"):
    for _, row in df_filtered.iterrows():
        st.markdown(f"**ğŸ§ª {row['US Product']}**ï¼ˆ{row['Ingredient']}ï¼‰")
        st.markdown(f"- è­¦ç¤ºæ—¥æœŸï¼š{row['Alert Date'].date()}ï½œä¾†æºï¼š{row['Source']}")
        st.markdown(f"- å°ç£é…å°ï¼š{row['TW Match Status']} â†’ `{row['TW Product']}`")
        st.markdown(f"- æ‘˜è¦ï¼š{row['Risk Summary']}")
        st.markdown(f"- å»ºè­°ï¼š{row['Action Summary']}")
        st.markdown(f"- è©³æƒ…ï¼š{row['FDA Excerpt']}")
        st.markdown("---")

# FDA å®˜ç¶²çˆ¬èŸ²æŒ‰éˆ•èˆ‡çµæœå‘ˆç¾
st.markdown("### ğŸ” æŠ“å–ä¸¦æ¯”å° FDA å®˜ç¶²è­¦ç¤º")
if st.button("ä¸€éµæ›´æ–°ä¸¦æ¯”å°"):
    latest_alerts = fetch_fda_dsc_alerts()
    fda_list_from_web = parse_dsc_to_fda_list(latest_alerts)
    df = pd.DataFrame(match_fda_to_tfda(fda_list_from_web, tfda_list))
    df["Alert Date"] = pd.to_datetime(df["Alert Date"])
    st.session_state["df"] = df

# è‹¥å·²æ›´æ–°ï¼Œé¡¯ç¤ºæ–°çµæœ
if "df" in st.session_state:
    st.markdown("### ğŸ“¬ æœ€æ–°æ¯”å°çµæœ")
    st.dataframe(st.session_state["df"], use_container_width=True)
