import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from difflib import SequenceMatcher
import os

# -------------------------
# æ¨™æº–åŒ–è™•ç†
# -------------------------
def normalize_text(text):
    if not text:
        return ""
    return (
        str(text).lower()
        .replace(" ", "")
        .replace("åŠ‘", "")
        .replace("æ³¨å°„æ¶²åŠ‘", "æ³¨å°„æ¶²")
        .replace("æ¯«å…‹", "mg")
        .replace("æ¯«å‡", "ml")
    )

# -------------------------
# é…å°æ¨¡çµ„
# -------------------------
def fuzzy_match(a, b):
    return SequenceMatcher(None, a, b).ratio()

def compute_match_score(fda, tfda):
    fda_ing = normalize_text(fda.get("ingredient", ""))
    tfda_ing = normalize_text(tfda.get("ingredient", ""))
    fda_form = normalize_text(fda.get("form", ""))
    tfda_form = normalize_text(tfda.get("form", ""))
    fda_prod = normalize_text(fda.get("us_product", ""))
    tfda_prod = normalize_text(tfda.get("tw_product", ""))

    score = 0.0
    if fda_ing and tfda_ing:
        if fda_ing == tfda_ing:
            score += 0.6
        elif fda_ing.split()[0] == tfda_ing.split()[0]:
            score += 0.5

    if fda_form and tfda_form:
        if fda_form == tfda_form:
            score += 0.3
        elif fda_form.split()[0] == tfda_form.split()[0]:
            score += 0.2

    if fda_prod and tfda_prod:
        sim = fuzzy_match(fda_prod, tfda_prod)
        if sim >= 0.85:
            score += 0.1
        elif sim >= 0.7:
            score += 0.05

    return round(score, 2)

def match_fda_to_tfda(fda_list, tfda_list):
    results = []
    for fda in fda_list:
        best_match = None
        best_score = 0.0
        for tfda in tfda_list:
            score = compute_match_score(fda, tfda)
            if score > best_score:
                best_score = score
                best_match = tfda
        if best_match and best_score >= 0.5:
            results.append({
                "Alert Date": fda["alert_date"],
                "Source": fda["source"],
                "US Product": fda["us_product"],
                "Ingredient": fda["ingredient"],
                "Risk Summary": fda["risk_summary"],
                "Action Summary": fda["action_summary"],
                "TW Match Status": "åŒä¸»æˆåˆ†" if best_score >= 0.85 else "ä¸­ä¿¡åº¦é…å°",
                "TW Product": best_match["tw_product"],
                "License ID": best_match["license_id"],
                "Strength/Form": best_match["form"],
                "Match Confidence": best_score,
                "FDA Excerpt": fda["fda_excerpt"]
            })
        else:
            results.append({
                "Alert Date": fda["alert_date"],
                "Source": fda["source"],
                "US Product": fda["us_product"],
                "Ingredient": fda["ingredient"],
                "Risk Summary": fda["risk_summary"],
                "Action Summary": fda["action_summary"],
                "TW Match Status": "ç„¡é…å°",
                "TW Product": "",
                "License ID": "",
                "Strength/Form": "",
                "Match Confidence": 0.0,
                "FDA Excerpt": fda["fda_excerpt"]
            })
    return results

# -------------------------
# FDA å®˜ç¶²çˆ¬èŸ² + æ–°è­¦ç¤ºç›£è¦–
# -------------------------
def fetch_fda_dsc_alerts():
    url = "https://www.fda.gov/drugs/drug-safety-and-availability/drug-safety-communications"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")

    alerts = []
    for item in soup.select(".view-content .views-row"):
        title_tag = item.select_one("h3 a")
        date_tag = item.select_one(".date-display-single")
        if title_tag and date_tag:
            alerts.append({
                "title": title_tag.text.strip(),
                "link": "https://www.fda.gov" + title_tag["href"],
                "date": date_tag.text.strip()
            })
    return alerts

def parse_dsc_to_fda_list(alerts):
    parsed = []
    for alert in alerts:
        parsed.append({
            "alert_date": pd.to_datetime(alert["date"], errors="coerce"),
            "source": "DSC",
            "us_product": alert["title"].split(":")[0].strip(),
            "ingredient": "",
            "form": "",
            "risk_summary": alert["title"],
            "action_summary": "è«‹åƒè€ƒåŸæ–‡",
            "fda_excerpt": f"è©³æƒ…è«‹è¦‹ï¼š{alert['link']}"
        })
    return parsed

def load_last_seen():
    if os.path.exists("last_seen_alerts.json"):
        try:
            return pd.read_json("last_seen_alerts.json")["title"].tolist()
        except:
            return []
    return []

def save_last_seen(alerts):
    titles = [a["title"] for a in alerts]
    pd.DataFrame({"title": titles}).to_json("last_seen_alerts.json")

def get_new_alerts():
    latest = fetch_fda_dsc_alerts()
    seen = load_last_seen()
    new_alerts = [a for a in latest if a["title"] not in seen]
    save_last_seen(latest)
    return new_alerts

# -------------------------
# é è¨­ FDA è—¥å“æ¸…å–®
# -------------------------
fda_list = [
    {
        "alert_date": "2025-11-01",
        "source": "DSC",
        "us_product": "Leqembi",
        "ingredient": "lecanemab",
        "form": "100 mg/mL æ³¨å°„æ¶²",
        "risk_summary": "é˜¿èŒ²æµ·é»˜ç—‡ ARIAï¼šAPOE Îµ4 æ”œå¸¶è€…é¢¨éšªå¢åŠ ",
        "action_summary": "å»ºè­°åŸºå› æª¢æ¸¬",
        "fda_excerpt": "FDA recommends MRI monitoring to reduce ARIA risk, especially in APOE Îµ4 carriers."
    },
    {
        "alert_date": "2025-10-15",
        "source": "DSC",
        "us_product": "Prolia",
        "ingredient": "denosumab",
        "form": "60 mg/1 mL æ³¨å°„æ¶²",
        "risk_summary": "åš´é‡ä½è¡€éˆ£ï¼šæ´—è…ç—…äººé¢¨éšªå¢åŠ ",
        "action_summary": "å»ºè­°ç›£æ¸¬è¡€éˆ£",
        "fda_excerpt": "Risk of severe hypocalcemia in dialysis patients receiving denosumab."
    }
]

# -------------------------
# Streamlit ä¸»ç•«é¢
# -------------------------
st.set_page_config(page_title="è—¥å“å®‰å…¨è­¦ç¤ºæ¯”å°å¹³å°", layout="wide")
st.title("è—¥å“å®‰å…¨è­¦ç¤ºæ¯”å°å¹³å°")

# ç›´æ¥è®€å–åŒç›®éŒ„ä¸‹çš„ 37_2b.csv
try:
    df_tfda = pd.read_csv("37_2b.csv")
    required_cols = ["tw_product", "ingredient", "form", "license_id"]
    if not all(col in df_tfda.columns for col in required_cols):
        st.error("37_2b.csv æ¬„ä½ç¼ºæ¼ï¼Œè«‹ç¢ºèªåŒ…å«ï¼štw_product, ingredient, form, license_id")
        tfda_list = []
    else:
        tfda_list = df_tfda[required_cols].to_dict(orient="records")
except Exception as e:
    st.error(f"è®€å– 37_2b.csv å¤±æ•—ï¼š{e}")
    tfda_list = []

df = pd.DataFrame(match_fda_to_tfda(fda_list, tfda_list))

# é˜²å‘†ï¼šç©ºè³‡æ–™
if df.empty:
    st.warning("âš ï¸ æ²’æœ‰é…å°çµæœï¼Œè«‹ç¢ºèª TFDA è³‡æ–™èˆ‡ FDA æ¸…å–®æ ¼å¼ã€‚")
    st.stop()

# é˜²å‘†ï¼šæ¬„ä½ç¼ºå¤±
if "Alert Date" in df.columns:
    df["Alert Date"] = pd.to_datetime(df["Alert Date"])
else:
    st.warning("âš ï¸ æ¬„ä½ 'Alert Date' ä¸å­˜åœ¨ï¼Œç„¡æ³•è½‰æ›æ—¥æœŸæ ¼å¼ã€‚")
    st.stop()

# KPI å¡ç‰‡
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric(label="æœ¬æœŸè­¦ç¤ºæ•¸", value=len(df))
with col2:
    st.metric(label="æ–°å¢é»‘æ¡†è­¦èªæ•¸", value=1)
with col3:
    st.metric(label="å°ç£æœ‰é…å°è—¥å“æ•¸", value=(df["TW Match Status"] != "ç„¡é…å°").sum())
with col4:
    st.metric(label="éœ€äººå·¥è¦†æ ¸æ•¸", value=(df["Match Confidence"] < 0.7).sum())

st.markdown("---")
# ç¯©é¸å™¨
st.sidebar.header("ç¯©é¸å™¨")
min_date = df["Alert Date"].min().date()
max_date = df["Alert Date"].max().date()
date_range = st.sidebar.date_input("è­¦ç¤ºæ—¥æœŸç¯„åœ", value=(min_date, max_date), min_value=min_date, max_value=max_date)
source_options = df["Source"].unique().tolist()
selected_sources = st.sidebar.multiselect("ä¾†æºé¡å‹", options=source_options, default=source_options)
keyword = st.sidebar.text_input("é—œéµå­—æœå°‹ï¼ˆå“å / æˆåˆ† / æ‘˜è¦ï¼‰", value="")

start_date, end_date = date_range if isinstance(date_range, tuple) else (min_date, max_date)
df_filtered = df[
    (df["Alert Date"] >= pd.to_datetime(start_date)) &
    (df["Alert Date"] <= pd.to_datetime(end_date)) &
    (df["Source"].isin(selected_sources))
]
if keyword.strip():
    kw = keyword.strip().lower()
    df_filtered = df_filtered[df_filtered.apply(lambda row: kw in str(row).lower(), axis=1)]

# ä¸»è¡¨æ ¼é¡¯ç¤º
st.markdown("### ğŸ“‹ é…å°çµæœä¸€è¦½")
st.dataframe(df_filtered, use_container_width=True)

# è©³æƒ…å±•é–‹
with st.expander("ğŸ“¦ å±•é–‹æ¯ç­†è­¦ç¤ºè©³æƒ…"):
    for _, row in df_filtered.iterrows():
        st.markdown(f"**ğŸ§ª {row['US Product']}**ï¼ˆ{row['Ingredient']}ï¼‰")
        st.markdown(f"- è­¦ç¤ºæ—¥æœŸï¼š{row['Alert Date'].date()}ï½œä¾†æºï¼š{row['Source']}")
        st.markdown(f"- å°ç£é…å°ï¼š{row['TW Match Status']} â†’ `{row['TW Product']}`")
        st.markdown(f"- æ‘˜è¦ï¼š{row['Risk Summary']}")
        st.markdown(f"- å»ºè­°ï¼š{row['Action Summary']}")
        st.markdown(f"- è©³æƒ…ï¼š{row['FDA Excerpt']}")
        st.markdown("---")

# FDA å®˜ç¶²çˆ¬èŸ²æŒ‰éˆ•
st.markdown("### ğŸ” ä¸€éµæŠ“å–ä¸¦æ¯”å° FDA å®˜ç¶²è­¦ç¤º")
if st.button("ç«‹å³æ›´æ–°"):
    latest_alerts = fetch_fda_dsc_alerts()
    fda_list_from_web = parse_dsc_to_fda_list(latest_alerts)
    df = pd.DataFrame(match_fda_to_tfda(fda_list_from_web, tfda_list))
    df["Alert Date"] = pd.to_datetime(df["Alert Date"])
    st.dataframe(df, use_container_width=True)

# ç¶²é ç›£è¦–ï¼šæª¢æŸ¥æ˜¯å¦æœ‰æ–°è­¦ç¤º
st.markdown("### ğŸ” æª¢æŸ¥ FDA å®˜ç¶²æ˜¯å¦æœ‰æ–°è­¦ç¤º")
if st.button("æª¢æŸ¥æ–°è­¦ç¤ºä¸¦æ¯”å°"):
    new_alerts = get_new_alerts()
    if new_alerts:
        st.success(f"ç™¼ç¾ {len(new_alerts)} ç­†æ–°è­¦ç¤ºï¼")
        fda_list_new = parse_dsc_to_fda_list(new_alerts)
        df_new = pd.DataFrame(match_fda_to_tfda(fda_list_new, tfda_list))
        df_new["Alert Date"] = pd.to_datetime(df_new["Alert Date"])
        st.dataframe(df_new, use_container_width=True)
    else:
        st.info("ç›®å‰æ²’æœ‰æ–°è­¦ç¤ºã€‚")

