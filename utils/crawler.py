import requests
from bs4 import BeautifulSoup
import json
import os

FDA_URL = "https://www.fda.gov/drugs/drug-safety-and-availability/drug-safety-communications"
CACHE_PATH = "data/fda_cache.json"

def fetch_fda_dsc_alerts():
    try:
        resp = requests.get(FDA_URL, timeout=10)
        soup = BeautifulSoup(resp.text, "html.parser")

        # æ”¹ç”¨æ›´ç©©å®šçš„é¸æ“‡å™¨
        alerts = []
        for item in soup.select("div.views-row a"):
            title = item.get_text(strip=True)
            link = item.get("href", "")
            if title and link:
                alerts.append({"title": title, "link": link})

        print("âœ… æˆåŠŸæŠ“å– FDA è­¦ç¤ºæ•¸é‡ï¼š", len(alerts))
        return alerts

    except Exception as e:
        print("âŒ æŠ“å– FDA å®˜ç¶²å¤±æ•—ï¼š", e)
        return []

def parse_dsc_to_fda_list(alerts):
    if not alerts:
        print("âš ï¸ è­¦ç¤ºæ¸…å–®ç‚ºç©ºï¼Œä½¿ç”¨å‚™æ´è³‡æ–™")
        from utils.fallback_data import fda_list
        return fda_list

    fda_list = []
    for alert in alerts[:3]:  # æ¸¬è©¦ç‰ˆï¼šåªå–å‰ä¸‰ç­†
        title = alert["title"].lower()
        if "prolia" in title:
            fda_list.append({
                "alert_date": "2025-11-01",
                "source": "FDA",
                "us_product": "Prolia",
                "ingredient": "denosumab",
                "form": "60 mg/1 mL æ³¨å°„æ¶²",
                "risk_summary": "Severe hypocalcemia in dialysis patients",
                "action_summary": "Monitor calcium levels",
                "fda_excerpt": f"https://www.fda.gov{alert['link']}"
            })
        elif "leqembi" in title:
            fda_list.append({
                "alert_date": "2025-11-01",
                "source": "FDA",
                "us_product": "Leqembi",
                "ingredient": "lecanemab",
                "form": "100 mg/mL æ³¨å°„æ¶²",
                "risk_summary": "Increased risk of brain swelling and bleeding",
                "action_summary": "FDA recommends genetic testing for APOE ARIA risk",
                "fda_excerpt": f"https://www.fda.gov{alert['link']}"
            })
        elif "jynarque" in title:
            fda_list.append({
                "alert_date": "2025-11-01",
                "source": "FDA",
                "us_product": "Jynarque",
                "ingredient": "tolvaptan",
                "form": "30 mg éŒ åŠ‘",
                "risk_summary": "Liver injury",
                "action_summary": "Monitor liver function",
                "fda_excerpt": f"https://www.fda.gov{alert['link']}"
            })
        else:
            fda_list.append({
                "alert_date": "2025-11-01",
                "source": "FDA",
                "us_product": alert["title"],
                "ingredient": "æœªçŸ¥",
                "form": "æœªçŸ¥",
                "risk_summary": "å°šæœªè§£æ",
                "action_summary": "è«‹åƒè€ƒ FDA åŸæ–‡æ‘˜è¦",
                "fda_excerpt": f"https://www.fda.gov{alert['link']}"
            })

    print("âœ… æˆåŠŸè§£æ fda_list æ•¸é‡ï¼š", len(fda_list))
    return fda_list

def get_new_alerts():
    latest = fetch_fda_dsc_alerts()
    latest_titles = {a["title"] for a in latest}

    if os.path.exists(CACHE_PATH):
        with open(CACHE_PATH, "r", encoding="utf-8") as f:
            cached = json.load(f)
        cached_titles = {a["title"] for a in cached}
    else:
        cached_titles = set()

    new_titles = latest_titles - cached_titles
    new_alerts = [a for a in latest if a["title"] in new_titles]

    # æ›´æ–°å¿«å–
    try:
        with open(CACHE_PATH, "w", encoding="utf-8") as f:
            json.dump(latest, f, ensure_ascii=False, indent=2)
        print("âœ… å¿«å–å·²æ›´æ–°")
    except Exception as e:
        print("âš ï¸ å¿«å–æ›´æ–°å¤±æ•—ï¼š", e)

    print(f"ğŸ” æ–°è­¦ç¤ºæ•¸é‡ï¼š{len(new_alerts)}")
    return new_alerts
